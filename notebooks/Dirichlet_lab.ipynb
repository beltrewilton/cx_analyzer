{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Grupo 4  - Proyecto `luiza` \n",
        "## Descubrir Tópicos basado en la técnica Latent Dirichlet Allocation [paper](https://www.jmlr.org/papers/volume3/blei03a/blei03a.pdf)\n",
        "### Esta aplicado utilizando la base de imdb previamente limpia para ir directo al punto."
      ],
      "metadata": {
        "id": "MrRs1cjvueTB"
      },
      "id": "MrRs1cjvueTB"
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/beltrewilton/cx_analyzer.git"
      ],
      "metadata": {
        "id": "-3WR42L1tCmL",
        "outputId": "933e3da6-07b6-4838-ad9c-a3305c1d2f33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "-3WR42L1tCmL",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'cx_analyzer'...\n",
            "remote: Enumerating objects: 22, done.\u001b[K\n",
            "remote: Counting objects: 100% (22/22), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 22 (delta 4), reused 16 (delta 1), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (22/22), 22.51 MiB | 8.25 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation"
      ],
      "metadata": {
        "id": "CRo4WUldrtVp"
      },
      "id": "CRo4WUldrtVp",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('./cx_analyzer/notebooks/dataset/movie_data_cleaned.csv', encoding='utf-8')\n",
        "count = CountVectorizer(stop_words='english', max_df=0.1, max_features=5000)\n",
        "X = count.fit_transform(df['review'].values)"
      ],
      "metadata": {
        "id": "KM3JPnXfvkIR"
      },
      "id": "KM3JPnXfvkIR",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Más información de la implementacion Dirichlet en :\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html"
      ],
      "metadata": {
        "id": "ALeNmz6ywHH_"
      },
      "id": "ALeNmz6ywHH_"
    },
    {
      "cell_type": "code",
      "source": [
        "# Esta tarea NLP para descubrir los tópicos consume tiempo, paciencia y café!\n",
        "\n",
        "lda = LatentDirichletAllocation(n_components=10, random_state=123, learning_method='batch')\n",
        "X_topics = lda.fit_transform(X)"
      ],
      "metadata": {
        "id": "4eq6cBbqvrfj"
      },
      "id": "4eq6cBbqvrfj",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación se hace selección de los top 5 tópicos por 10 componentes encontrados."
      ],
      "metadata": {
        "id": "SN0NBLPSvyrq"
      },
      "id": "SN0NBLPSvyrq"
    },
    {
      "cell_type": "code",
      "source": [
        "n_top_words = 5\n",
        "feature_names = count.get_feature_names_out()\n",
        "for topic_idx, topic in enumerate(lda.components_, 1):\n",
        "    print(f'Topic {topic_idx}')\n",
        "    print(' '.join([feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]]))"
      ],
      "metadata": {
        "id": "y_5lz8_sv4ZF",
        "outputId": "90463d96-547d-4346-a3f2-0cb5e8c62d63",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "y_5lz8_sv4ZF",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 1\n",
            "horror original comedy black house\n",
            "Topic 2\n",
            "worst minutes guy script money\n",
            "Topic 3\n",
            "book dvd read version watched\n",
            "Topic 4\n",
            "family performance father beautiful mother\n",
            "Topic 5\n",
            "series episode tv kids comedy\n",
            "Topic 6\n",
            "murder police wife john plays\n",
            "Topic 7\n",
            "documentary camera effects audience sense\n",
            "Topic 8\n",
            "music song songs musical role\n",
            "Topic 9\n",
            "horror effects guy dead budget\n",
            "Topic 10\n",
            "action war game fight american\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que sigue?\n",
        "Mi recomendación es que miremos una implementación aún más robusta de Dirichlet sobre Deep Learning desarrollada por la empresa Uber llamada Pyro, más información:\n",
        "\n",
        "*   https://medium.com/@anmolmittal_28682/evaluate-probabilistic-topic-models-pyro-latent-dirichlet-allocation-b84b73d110a7\n",
        "*   https://pyro.ai/examples/intro_long.html\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ugx3rZy8wd5L"
      },
      "id": "ugx3rZy8wd5L"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}